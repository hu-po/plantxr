<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<html>

<head>
  <meta charset='utf-8'>
  <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
  <meta name='mobile-web-app-capable' content='yes'>
  <meta name='apple-mobile-web-app-capable' content='yes'>
  <link rel='icon' type='image/png' sizes='32x32' href='favicon-32x32.png'>
  <link rel='icon' type='image/png' sizes='96x96' href='favicon-96x96.png'>
  <link rel='stylesheet' href='css/common.css'>

  <title>Stereo Video Player</title>
</head>

<body>
  <header>
    <details open>
      <summary>Stereo Video Player</summary>
      <p>
        This sample demonstrates how to play a stereo 3D video.
        <a class="back" href="./">Back</a>
        <br />
        <hr />
        Autoplay when VR starts: <input id='autoplayVideo' type='checkbox' />
      </p>
      </summary>
  </header>
  <script type="module">
    import { WebXRButton } from './js/util/webxr-button.js';
    import { Scene } from './js/render/scenes/scene.js';
    import { Renderer, createWebGLContext } from './js/render/core/renderer.js';
    import { UrlTexture } from './js/render/core/texture.js';
    import { ButtonNode } from './js/render/nodes/button.js';
    // import {Gltf2Node} from './js/render/nodes/gltf2.js';
    import { VideoNode } from './js/render/nodes/video.js';
    import { InlineViewerHelper } from './js/util/inline-viewer-helper.js';
    import { QueryArgs } from './js/util/query-args.js';

    // If requested, use the polyfill to provide support for mobile devices
    // and devices which only support WebVR.
    import WebXRPolyfill from './js/third-party/webxr-polyfill/build/webxr-polyfill.module.js';
    if (QueryArgs.getBool('usePolyfill', true)) {
      let polyfill = new WebXRPolyfill();
    }

    let autoplayCheckbox = document.getElementById('autoplayVideo');

    // XR globals.
    let xrButton = null;
    let xrImmersiveRefSpace = null;
    let inlineViewerHelper = null;

    // WebGL scene globals.
    let gl = null;
    let renderer = null;
    let scene = new Scene();
    // scene.addNode(new Gltf2Node({url: 'media/gltf/home-theater/home-theater.gltf'}));
    scene.enableStats(false);

    let video = document.createElement('video');
    video.loop = true;
    // video.src = 'media/video/bbb-sunflower-540p2-1min.webm';
    video.src = 'media/video/output.webm';

    let videoNode = new VideoNode({
      video: video,
      displayMode: 'stereoTopBottom'
    });

    // When the video is clicked we'll pause it if it's playing.
    videoNode.onSelect(() => {
      if (!video.paused) {
        playButton.visible = true;
        video.pause();
      } else {
        playButton.visible = false;
        video.play();
      }
    });
    videoNode.selectable = true;

    // Move back to the position of the in-room screen and size to cover it.
    // Values determined experimentally and with many refreshes.
    videoNode.translation = [0.025, 0.275, -4.4];
    videoNode.scale = [2.1, 1.1, 1.0];
    scene.addNode(videoNode);

    video.addEventListener('loadeddata', () => {
      // Once the video has loaded up adjust the aspect ratio of the "screen"
      // to fit the video's native shape.
      let aspect = videoNode.aspectRatio;
      if (aspect < 2.0) {
        videoNode.scale = [aspect * 1.1, 1.1, 1.0];
      } else {
        videoNode.scale = [2.1, 2.1 / aspect, 1.0];
      }
    });

    // Add a button to the scene to play/pause the movie.
    let playTexture = new UrlTexture('media/textures/play-button.png');

    // Create a button that plays the video when clicked.
    let playButton = new ButtonNode(playTexture, () => {
      // Play the video and hide the button.
      if (video.paused) {
        playButton.visible = false;
        video.play();
      }
    });
    // Move the play button to the center of the screen and make it much
    // bigger.
    playButton.translation = [0.025, 0.275, -4.2];
    playButton.scale = [5.0, 5.0, 5.0];
    scene.addNode(playButton);

    function initXR() {
      xrButton = new WebXRButton({
        onRequestSession: onRequestSession,
        onEndSession: onEndSession
      });
      document.querySelector('header').appendChild(xrButton.domElement);

      if (navigator.xr) {
        navigator.xr.isSessionSupported('immersive-vr').then((supported) => {
          xrButton.enabled = supported;
        });

        navigator.xr.requestSession('inline').then(onSessionStarted);
      }
    }

    function initGL() {
      if (gl)
        return;

      gl = createWebGLContext({
        xrCompatible: true
      });
      document.body.appendChild(gl.canvas);

      function onResize() {
        gl.canvas.width = gl.canvas.clientWidth * window.devicePixelRatio;
        gl.canvas.height = gl.canvas.clientHeight * window.devicePixelRatio;
      }
      window.addEventListener('resize', onResize);
      onResize();

      renderer = new Renderer(gl);
      scene.setRenderer(renderer);
    }

    function onRequestSession() {
      let autoplay = autoplayCheckbox.checked;

      let pending;

      if (autoplay) {
        // If we want the video to autoplay when the session has fully started
        // (which may be several seconds after the original requestSession
        // call due to clicking through consent prompts or similar) then we
        // need to start the video within a user activation event first
        // (which this function is.) Once it's been started successfully we
        // pause it, at which point we can resume it pretty much whenever we'd
        // like.
        pending = video.play().then(() => {
          video.pause();
        });
      }

      return navigator.xr.requestSession('immersive-vr', {
        requiredFeatures: ['local-floor']
      }).then((session) => {
        xrButton.setSession(session);
        session.isImmersive = true;
        onSessionStarted(session);

        if (autoplay) {
          pending.then(() => {
            video.play();
          });
        }
      });
    }

    function onSessionStarted(session) {
      session.addEventListener('end', onSessionEnded);
      session.addEventListener('select', (ev) => {
        let refSpace = ev.frame.session.isImmersive ?
          xrImmersiveRefSpace :
          inlineViewerHelper.referenceSpace;
        scene.handleSelect(ev.inputSource, ev.frame, refSpace);
      });

      initGL();
      scene.inputRenderer.useProfileControllerMeshes(session);

      let glLayer = new XRWebGLLayer(session, gl);
      session.updateRenderState({ baseLayer: glLayer });

      // In this case we're going to use an 'local' frame of reference
      // because we want to users head to appear in the right place relative
      // to the center chair, as if they're sitting in it, rather than
      // somewhere in the room relative to the floor.
      let refSpaceType = session.isImmersive ? 'local' : 'viewer';
      session.requestReferenceSpace(refSpaceType).then((refSpace) => {
        if (session.isImmersive) {
          xrImmersiveRefSpace = refSpace;
        } else {
          inlineViewerHelper = new InlineViewerHelper(gl.canvas, refSpace);
        }

        session.requestAnimationFrame(onXRFrame);
      });
    }

    function onEndSession(session) {
      session.end();
    }

    function onSessionEnded(event) {
      if (event.session.isImmersive) {
        xrButton.setSession(null);
        video.pause();
      }
    }

    function onXRFrame(t, frame) {
      let session = frame.session;
      let refSpace = session.isImmersive ?
        xrImmersiveRefSpace :
        inlineViewerHelper.referenceSpace;
      let pose = frame.getViewerPose(refSpace);

      if (pose) {
        // Get the transform of the viewer's head.
        let headTransform = pose.transform;

        // Update the position and orientation of the video node to match the viewer's head.
        videoNode.matrix = headTransform.matrix;
        videoNode.updateMatrixWorld();
      }

      scene.startFrame();

      session.requestAnimationFrame(onXRFrame);

      scene.updateInputSources(frame, refSpace);

      scene.drawXRFrame(frame, pose);

      scene.endFrame();
    }

    // Globals for robot arm
    let servos = [0, 0, 0];

    // Boxes for robotic arm
    let boxes_arm = [];
    const defaultBoxColor = { r: 0.5, g: 0.5, b: 0.5 };
    const joint1BoxColor = { r: 1, g: 0, b: 0 };
    const joint2BoxColor = { r: 0, g: 1, b: 0 };
    const joint3BoxColor = { r: 0, g: 0, b: 1 };

    function createBoxPrimitive(r, g, b) {
      let boxBuilder = new BoxBuilder();
      boxBuilder.pushCube([0, 0, 0], 1);
      let boxPrimitive = boxBuilder.finishPrimitive(renderer);
      let boxMaterial = new PbrMaterial();
      boxMaterial.baseColorFactor.value = [r, g, b, 1];
      return renderer.createRenderPrimitive(boxPrimitive, boxMaterial);
    }

    function addBox(x, y, z, r, g, b) {
      let boxRenderPrimitive = createBoxPrimitive(r, g, b);
      let boxNode = new Node();
      boxNode.addRenderPrimitive(boxRenderPrimitive);
      boxNode.selectable = true;  // Marks the node as one that needs to be checked when hit testing.
      return boxNode;
    }

    function initRobotArm() {
      // Clear previous boxes
      for (const box of boxes_arm) {
        scene.removeNode(box);
      }
      boxes_arm = [];

      // Add boxes for each segment of the robotic arm
      boxes_arm.push(addBox(0, 0, 0, joint1BoxColor.r, joint1BoxColor.g, joint1BoxColor.b));  // Joint 1
      boxes_arm.push(addBox(0, 0, 0, joint2BoxColor.r, joint2BoxColor.g, joint2BoxColor.b));  // Joint 2
      boxes_arm.push(addBox(0, 0, 0, joint3BoxColor.r, joint3BoxColor.g, joint3BoxColor.b));  // Joint 3
    }

    function updateServoAngles() {
      fetch('/api/servos')
        .then(response => response.json())
        .then(data => {
          servos = data.servos;

          // Assuming the boxes are unit length.
          const boxLength = 1;

          // Update the first joint (base joint)
          let baseRotation = servos[0] * (Math.PI / 180);  // Convert to radians
          boxes_arm[0].rotation = [0, baseRotation, 0];
          boxes_arm[0].translation = [0, 0, 0];

          // Update the second joint (mid-joint)
          let midRotation = servos[1] * (Math.PI / 180);
          boxes_arm[1].rotation = [0, 0, midRotation];
          boxes_arm[1].translation = [0, boxLength, 0];  // Positioned above the base joint

          // Update the third joint (top joint)
          let topRotation = servos[2] * (Math.PI / 180);
          boxes_arm[2].rotation = [0, 0, topRotation];
          boxes_arm[2].translation = [0, 2 * boxLength, 0];  // Positioned above the mid-joint
        });
    }

    // Update angles every 1 second
    setInterval(updateServoAngles, 1000);
    // Start the XR application.
    initXR();
  </script>
</body>

</html>